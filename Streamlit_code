import streamlit as st
from ultralytics import YOLO
import tempfile
from PIL import Image
import cv2
import os
import numpy as np

# Load YOLOv8 model directly from .pt file
model = YOLO("best.pt")

st.title("ðŸš¦ Traffic Sign Detection")

# Choose input type
input_type = st.radio("Select input type:", ('Image', 'Video'))

# Handle Image input
if input_type == 'Image':
    uploaded_image = st.file_uploader("Upload an image", type=["jpg", "jpeg", "png"])

    if uploaded_image:
        image = Image.open(uploaded_image)
        st.image(image, caption="Uploaded Image", use_column_width=True)

        # Convert PIL image to OpenCV format
        image_cv = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)

        # Run detection
        results = model(image_cv)[0]
        annotated_img = results.plot()

        st.image(annotated_img, caption="Detected Image", use_column_width=True)

# Handle Video input
elif input_type == 'Video':
    uploaded_video = st.file_uploader("Upload a video", type=["mp4", "avi", "mov"])

    if uploaded_video:
        tfile = tempfile.NamedTemporaryFile(delete=False)
        tfile.write(uploaded_video.read())
        video_path = tfile.name

        st.video(video_path)
        st.write("Running detection...")

        cap = cv2.VideoCapture(video_path)
        output_frames = []

        while cap.isOpened():
            ret, frame = cap.read()
            if not ret:
                break

            results = model(frame)[0]
            annotated_frame = results.plot()
            output_frames.append(annotated_frame)

        cap.release()

        # Show last detected frame
        st.image(output_frames[-1], caption="Last frame with detections")

